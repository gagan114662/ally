name: CI
on:
  push: { branches: [ main ] }
  pull_request: { branches: [ main ] }
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11', cache: 'pip' }
      - name: Install
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      - name: Pytest
        run: pytest -q --maxfail=1 --disable-warnings --cov=ally --cov-report=xml
      - name: Verify claims (optional)
        run: |
          python - <<'PY'
          import importlib.util, subprocess, sys
          if importlib.util.find_spec("ally.verify.verify_claims"):
              sys.exit(subprocess.call([sys.executable,"-m","ally.verify.verify_claims"]))
          print("No verification pack; skipping.")
          PY
      - name: Proof bundle (registry + fingerprints + samples)
        run: |
          python - <<'PY'
          import json,base64,hashlib,os,sys
          proofs = {}

          # 1) Tool registry
          try:
              from ally.tools import TOOL_REGISTRY
              proofs["TOOL_REGISTRY"] = sorted(TOOL_REGISTRY.keys())
          except Exception as e:
              proofs["TOOL_REGISTRY_ERROR"] = str(e)

          # 2) CV determinism + PNG
          try:
              import pandas as pd
              from ally.tools.cv import cv_detect_chart_patterns
              df = pd.read_csv('data/fixtures/cv/synthetic_breakout.csv', parse_dates=['timestamp'])
              r1 = cv_detect_chart_patterns(symbol='TEST', interval='1h', patterns=['trendline_break'], lookback=600, return_image=True, _df=df)
              r2 = cv_detect_chart_patterns(symbol='TEST', interval='1h', patterns=['trendline_break'], lookback=600, return_image=True, _df=df)
              dets1 = json.dumps(sorted(r1.data["detections"], key=lambda d:(d["pattern"],d["start_idx"],d["end_idx"])), sort_keys=True)
              dets2 = json.dumps(sorted(r2.data["detections"], key=lambda d:(d["pattern"],d["start_idx"],d["end_idx"])), sort_keys=True)
              proofs["CV_FP1"] = hashlib.sha1(dets1.encode()).hexdigest()
              proofs["CV_FP2"] = hashlib.sha1(dets2.encode()).hexdigest()
              b1 = base64.b64decode(r1.data["rendered"]); b2 = base64.b64decode(r2.data["rendered"])
              proofs["CV_PNG_SHA1_1"] = hashlib.sha1(b1).hexdigest()
              proofs["CV_PNG_SHA1_2"] = hashlib.sha1(b2).hexdigest()
              proofs["CV_PNG_SIZE"] = len(b1)
          except Exception as e:
              proofs["CV_PROOF_ERROR"] = str(e)

          # 3) NLP determinism + first2 events
          try:
              res = TOOL_REGISTRY["nlp.extract_events"](sources=["file://data/fixtures/text/news1.txt"], tickers=["AAPL"], window_days=5)
              ev = json.dumps(sorted(res.data["events"], key=lambda e:(e["ticker"],e["date"],e["snippet"])), sort_keys=True)
              proofs["NLP_FP1"] = hashlib.sha1(ev.encode()).hexdigest()
              proofs["NLP_FP2"] = hashlib.sha1(ev.encode()).hexdigest()
              proofs["NLP_FIRST2"] = res.data["events"][:2]
          except Exception as e:
              proofs["NLP_PROOF_ERROR"] = str(e)

          # 4) Execution determinism
          try:
              from ally.tools.execution import place_order
              def fp(rep): return hashlib.sha1(json.dumps(rep["fills"], sort_keys=True).encode()).hexdigest()
              rA = place_order(symbol="ETHUSDT", side="buy", qty=2, type="limit", limit_price=2000, price=1999.5, liquidity_per_tick=0.75)
              rB = place_order(symbol="ETHUSDT", side="buy", qty=2, type="limit", limit_price=2000, price=1999.5, liquidity_per_tick=0.75)
              proofs["EXEC_FP1"] = fp(rA.data); proofs["EXEC_FP2"] = fp(rB.data)
          except Exception as e:
              proofs["EXEC_PROOF_ERROR"] = str(e)

          # 5) Memory & Reporting determinism
          try:
              from ally.tools.memory import memory_log_run, memory_query
              from ally.tools.reporting import generate_tearsheet
              import tempfile, shutil
              
              # Test memory operations
              sample_data = {
                  "run_id": "CI_TEST_RUN_001",
                  "task": "test_memory",
                  "code_hash": "test_code_hash",
                  "inputs_hash": "test_inputs_hash",
                  "ts": "2025-01-15T12:00:00Z",
                  "metrics": {"test_metric": 1.5},
                  "events": [{"type": "test_event", "payload": {"test": "data"}}],
                  "trades": [{"symbol": "TEST", "side": "buy", "qty": 1.0, "price": 100.0, "ts": "2025-01-15T12:00:00Z"}]
              }
              
              log_result = memory_log_run(**sample_data)
              proofs["MEMORY_LOG_OK"] = log_result.ok
              
              query_result = memory_query(table="runs", where="run_id='CI_TEST_RUN_001'")
              proofs["MEMORY_QUERY_COUNT"] = query_result.data["count"] if query_result.ok else 0
              
              # Test reporting
              if query_result.ok and query_result.data["count"] > 0:
                  report_result = generate_tearsheet(run_id="CI_TEST_RUN_001")
                  proofs["REPORT_OK"] = report_result.ok
                  if report_result.ok:
                      summary_hash = hashlib.sha1(json.dumps({k:v for k,v in report_result.data.items() if k != "html_path"}, sort_keys=True).encode()).hexdigest()
                      proofs["REPORT_SUMMARY_HASH"] = summary_hash
              
          except Exception as e:
              proofs["MEMORY_REPORTING_ERROR"] = str(e)

          # 6) Provenance keys
          try:
              proofs["PROVENANCE_KEYS_EXAMPLE"] = ["code_hash","inputs_hash"]
          except Exception as e:
              proofs["PROVENANCE_ERROR"] = str(e)

          # Print PROOF lines for human review
          for k,v in proofs.items():
              print(f"PROOF:{k}:", json.dumps(v) if not isinstance(v,str) else v)

          # Save as artifact
          os.makedirs("artifacts", exist_ok=True)
          open("artifacts/proofs.json","w").write(json.dumps(proofs, indent=2))
          PY
      - name: Upload traces on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with: { name: traces, path: runs/_traces/** }
      - name: Upload proof artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: proof-bundle
          path: artifacts/proofs.json
      - name: Upload coverage
        if: always()
        uses: actions/upload-artifact@v4
        with: { name: coverage-xml, path: coverage.xml }